{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()\n",
    "\n",
    "class Config():\n",
    "    training_dir = \"/content/drive/MyDrive/siamese-net/content/sign_data/train\"\n",
    "    testing_dir = \"/content/drive/MyDrive/siamese-net/content/sign_data/test\"\n",
    "    train_batch_size = 64\n",
    "    train_number_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.cnn1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(4, kernel_size=3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(8, kernel_size=3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(8, kernel_size=3, padding='same', activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization()\n",
    "        ])\n",
    "        \n",
    "        self.fc1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(500, activation='relu'),\n",
    "            tf.keras.layers.Dense(500, activation='relu'),\n",
    "            tf.keras.layers.Dense(5)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = self.fc1(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, imageFolderDataset, transform=None, should_invert=True):\n",
    "        self.imageFolderDataset = imageFolderDataset\n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.filepaths)\n",
    "        should_get_same_class = random.randint(0, 1)\n",
    "\n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.filepaths)\n",
    "                if self.imageFolderDataset.directory == os.path.dirname(img1_tuple):\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.filepaths)\n",
    "                if self.imageFolderDataset.directory != os.path.dirname(img1_tuple):\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple)\n",
    "        img1 = Image.open(img1_tuple)\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        img0 = np.array(img0)\n",
    "        img1 = np.array(img1)\n",
    "\n",
    "        img0 = np.expand_dims(img0, axis=-1)\n",
    "        img1 = np.expand_dims(img1, axis=-1)\n",
    "\n",
    "        img0 = tf.image.resize(img0, (100, 100))\n",
    "        img1 = tf.image.resize(img1, (100, 100))\n",
    "\n",
    "        label = int(self.imageFolderDataset.directory != os.path.dirname(img1_tuple))\n",
    "        label = np.array([label], dtype=np.float32)\n",
    "\n",
    "        return (img0, img1), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "folder_dataset = image_datagen.flow_from_directory(\n",
    "    directory=Config.training_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "siamese_dataset = SiameseNetworkDataset(\n",
    "    imageFolderDataset=folder_dataset,\n",
    "    transform=None,\n",
    "    should_invert=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dataloader = tf.data.Dataset.from_generator(\n",
    "    lambda: siamese_dataset,\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(100, 100, 1), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(100, 100, 1), dtype=tf.float32)),\n",
    "        tf.TensorSpec(shape=(2,), dtype=tf.float32)\n",
    "    )\n",
    ").shuffle(buffer_size=len(siamese_dataset)).batch(8).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "print(vis_dataloader)\n",
    "dataiter = iter(vis_dataloader)\n",
    "print(dataiter)\n",
    "example_batch = next(dataiter)\n",
    "print(example_batch)\n",
    "\n",
    "concatenated = tf.concat([example_batch[0][0], example_batch[0][1]], axis=0)\n",
    "\n",
    "grid = tf.squeeze(tf.concat(tf.unstack(concatenated), axis=-2))\n",
    "plt.imshow(grid, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(example_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, margin=2.0, **kwargs):\n",
    "        super(ContrastiveLoss, self).__init__(**kwargs)\n",
    "        self.margin = margin\n",
    "\n",
    "    def call(self, output1, output2, label):\n",
    "        euclidean_distance = tf.norm(output1 - output2, axis=-1, keepdims=True)\n",
    "        loss_contrastive = tf.reduce_mean((1 - label) * tf.square(euclidean_distance) +\n",
    "                                          label * tf.square(tf.maximum(0.0, self.margin - euclidean_distance)))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataloader = tf.data.Dataset.from_generator(\n",
    "    lambda: siamese_dataset,\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(100, 100, 1), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(100, 100, 1), dtype=tf.float32)),\n",
    "        tf.TensorSpec(shape=(1,), dtype=tf.float32)\n",
    "    )\n",
    ").shuffle(buffer_size=len(siamese_dataset)).batch(Config.train_batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "net = SiameseNetwork()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "counter = []\n",
    "loss_history = []\n",
    "iteration_number = 0\n",
    "\n",
    "@tf.function\n",
    "def train_step(img0, img1, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output1, output2 = net(img0, img1)\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "    gradients = tape.gradient(loss_contrastive, net.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
    "    return loss_contrastive\n",
    "\n",
    "for epoch in range(Config.train_number_epochs):\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        img0, img1, label = data\n",
    "        loss = train_step(img0, img1, label)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch, loss.numpy()))\n",
    "            iteration_number += 10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss.numpy())\n",
    "\n",
    "net.save_weights(\"siamese_model.h5\")\n",
    "show_plot(counter, loss_history)\n",
    "\n",
    "\n",
    "# folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
    "folder_dataset_test = dset.ImageFolder(root=\"/content/drive/MyDrive/siamese-net/content/sign_data/jeong\")\n",
    "\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       ,should_invert=False)\n",
    "\n",
    " \n",
    "\n",
    "test_dataloader = DataLoader(siamese_dataset,num_workers=6,batch_size=1,shuffle=True)\n",
    "\n",
    "dataiter = iter(test_dataloader)\n",
    "x0,_,_ = next(dataiter)\n",
    "\n",
    "for i in range(10):\n",
    "    _,x1,label2 = next(dataiter)\n",
    "    concatenated = torch.cat((x0,x1),0)\n",
    "\n",
    "    output1,output2 = net(Variable(x0).cuda(),Variable(x1).cuda())\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f}'.format(euclidean_distance.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load dataset\n",
    "dataset, info = tfds.load('image_folder', split='test', data_dir=Config.testing_dir, with_info=True)\n",
    "\n",
    "# Define image preprocessing function\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, (100, 100))\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "# Create SiameseNetworkDataset class\n",
    "class SiameseNetworkDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.dataset[index]\n",
    "        img0 = preprocess_image(sample['image'])\n",
    "        label0 = sample['label']\n",
    "        \n",
    "        should_get_same_class = np.random.randint(0, 2)\n",
    "        \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                sample_same = self.dataset[np.random.randint(len(self.dataset))]\n",
    "                if sample_same['label'] == label0:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                sample_diff = self.dataset[np.random.randint(len(self.dataset))]\n",
    "                if sample_diff['label'] != label0:\n",
    "                    break\n",
    "        \n",
    "        img1 = preprocess_image(sample_same['image'])\n",
    "        label1 = sample_same['label']\n",
    "        \n",
    "        img0 = tf.expand_dims(img0, axis=-1)\n",
    "        img1 = tf.expand_dims(img1, axis=-1)\n",
    "        \n",
    "        return img0, img1, label0, label1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "# Create SiameseNetwork model\n",
    "def SiameseNetwork():\n",
    "    # Define your model architecture here\n",
    "    pass\n",
    "\n",
    "# Load trained model\n",
    "model = SiameseNetwork()\n",
    "\n",
    "siamese_dataset = SiameseNetworkDataset(dataset, transform=preprocess_image)\n",
    "\n",
    "test_dataloader = tf.data.Dataset.from_generator(\n",
    "    lambda: siamese_dataset,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(100, 100, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(100, 100, 1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int64),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int64)\n",
    "    )\n",
    ").batch(1)\n",
    "\n",
    "dataiter = iter(test_dataloader)\n",
    "x0, _, label0, _ = next(dataiter)\n",
    "\n",
    "for i in range(10):\n",
    "    _, x1, _, label1 = next(dataiter)\n",
    "    concatenated = tf.concat([x0, x1], axis=0)\n",
    "\n",
    "    output1, output2 = net(x0, x1)\n",
    "    euclidean_distance = tf.norm(output1 - output2, ord='euclidean')\n",
    "\n",
    "    plt.imshow(np.squeeze(concatenated), cmap='gray')\n",
    "    plt.title('Dissimilarity: {:.2f}'.format(euclidean_distance.numpy()))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_siamese",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
